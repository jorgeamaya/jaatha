% \VignetteIndexEntry{The Jaatha HowTo}
% \VignetteDepends{jaatha}
% \VignettePackage{jaatha}
% \VignetteEngine{knitr::knitr}

\documentclass[a4paper]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{textcomp}

\usepackage{natbib}
\usepackage{graphics}
\usepackage{amsmath}
\usepackage{indentfirst}
\usepackage{hyperref}

<<setup, include=FALSE, echo=FALSE>>=
options(keep.source = TRUE, width = 50)
jinfo <- packageDescription("jaatha")
opts_chunk$set(error = FALSE)
@

\hypersetup{
	pdftitle={The Jaatha HowTo \Sexpr{jinfo$Version}},
	pdfauthor={\Sexpr{jinfo$Author}},
	colorlinks=true,
	linkcolor=black,      % color of internal links
	citecolor=black,      % color of links to bibliography
	filecolor=black,      % color of file links
	urlcolor=blue         % color of external links
}


\begin{document}


\title{The Jaatha HowTo}
\author{\Sexpr{jinfo$Author}}
\date{Version \Sexpr{jinfo$Version}}
\maketitle

\section{Introduction}
\noindent
Jaatha is a fast composite likelihood method to estimate model parameters of the
evolutionary history of (at the moment) two related species or populations.
To do so, it uses SNP data from multiple individuals from both species and -- optionally but
highly recommended -- one or more outgroup sequences.
This HowTo describes the method and gives an example of using its implementation
as \verb@R@ package \verb@jaatha@.

The package itself can be obtained from CRAN
using
<<install, eval=FALSE>>=
install.packages('jaatha')
@ 
\noindent
or downloaded from
\url{http://evol.bio.lmu.de/_statgen/software/jaatha}. Jaatha runs on R under Windows, 
OS X (Mac) and Linux  with the following restrictions: On Windows the parallelization 
and finite sites simulation using Seq-Gen is currently not supported.

A more detailed description of the algorithm can be found in
\cite{mathew_why_2013}. 
Further information about the
\verb@R@ functions used in this document can be obtained by calling 
\verb@help()@ with the functions name as argument.

We kindly ask you to cite the above paper when using Jaatha in a publication.


\section{A demographic model}
\noindent
Before we can apply Jaatha to estimate parameters, we first need to create a model
of the evolutionary history of the two species. Jaatha cannot account for the
effects of selection, hence we assume a neutral evolution. It can estimate the 
effects that either ``demographic'' events -- like an expansion of the
size of one population or migration between the two populations -- or molecular events --
like mutation or recombination -- have on the genome of the populations. To
emphasize that we can not include selection, we refer to a scenario of the
evolution of the two species under such events as a ``demographic model''.

For now, assume that we know that our two species are closely related; hence they must 
have separated at a certain time in the past. There may still be gene flow
ongoing between them 
to which we will refer to as migration from one population into the other. 
Hence, we could propose the simple demographic model described in Figure~\ref{fig:dm}.

\begin{figure}
\begin{center}
\includegraphics[width=60mm]{img/dm.png}
\end{center}
\caption{
A simple demographic model: The ancestral population splits into two populations $\tau$ time 
units ago, and afterwards individuals migrated from one population to the other with a 
migration rate $M$. Mutations are occurring with rate $\theta$ and recombination with a 
known rate $\rho$.}
\label{fig:dm}
\end{figure}

To specify that model in \verb@R@, we first need to load \verb@jaatha@.
<<loadingJaatha>>=
library(jaatha)
@
We can now create an 'empty' demographic model \verb@dm@ using the\\ 
\verb@dm.createDemographicModel()@ function:

<<creatingDm>>=
dm <- dm.createDemographicModel(sample.sizes=c(12,14),
                                loci.num=50,
                                seq.length=1000)
@

\noindent
The parameter \verb@sample.sizes@ here corresponds to the number of individuals we have
sampled from the first population and second population respectively. The 
second argument \verb@loci.num@ states that we are using data from $70$ loci
while \verb@seq.length@ gives the (average) length of each loci\footnote{This 
is only used when a finite sites model is assumed or if intra-locus recombination is included.}.

We can now successively add the other assumptions of our model:
<<addingFeaturesToDM>>=
dm <- dm.addSpeciationEvent(dm, .1, 5, new.time.point.name='tau')
dm <- dm.addSymmetricMigration(dm, .01, 5, new.par.name='M')
dm <- dm.addMutation(dm, 1, 20, new.par.name='theta')
dm <- dm.addRecombination(dm, fixed=20)
@
\noindent
The first parameter is the demographic model to which we want to add
an assumption/feature. The two following numbers represent the range for the
corresponding parameter. 
The lower border has to be strictly greater the zero, as we are using a logarithmic transformation
of the parameter space. The parameters are scaled as in the popular simulation program
\verb@ms@ \citep{hudson_generating_2002} that we use for simulations:
\begin{itemize}
\item The parameter for the \emph{speciation} event is the split time $\tau$, which
	states how many generations ago the split of the population has occurred.
	As usual in population genetics, it is measured in units of $4N_1$ 
	generations ago, where $N_1$ is the (diploid) effective population size of 
	the first population.
\item The parameter for the (symmetric) \emph{migration} is the scaled migration rate $M$, 
	which is given by $M=4N_1m$, where $m$ is the fraction of individuals of each 
	population which are replaced by immigrants from the other population each
	generation.
\item The \emph{mutation} parameter $\theta$ is $4N_1$ times the neutral mutation
	rate per locus.
\item Finally, the \emph{recombination} parameter $\rho$ is $4N_1$ times
	the probability of recombination between the ends of the locus per generation.
\end{itemize}

\noindent
%Finally we can check your model using
%<<Checking the model>>=
%dm
%@

\noindent
Keep in mind that a `good' model -- which is one that approximates the real demographic
history but is also as simple as possible -- is crucial for obtaining meaningful
estimates in the end. Jaatha will always try to find the parameters that make the
model fit best to your data. If the model does not fit to the data at all,
Jaatha will still return estimates, but they will not be meaningful.

\section{Theoretical Background}
\noindent
It is important to understand the key concepts behind Jaatha before we can apply it. Like many
estimation methods that rely on simulations, Jaatha tries to find the parameters that best fits
\footnote{for Jaatha, the 'best' parameter combination is the one with the highest
composite likelihood} to your data by simulating artificial data for many different parameter
combinations. It uses a learning algorithm to determine how the different parameter
values influence the simulated data and uses that knowledge to find the best parameter combination for 
your data. 

You can imagine Jaatha as a method that runs through the parameter space -- the space
of all possible parameter combinations, in our example a cube with borders from $0.1$ to $5$, 
$0.01$ to $5$ and $1$ to $20$ -- simulating in a small part of the parameter space
around the current position (we call this area a \emph{block}). It then searches the new maximum
of the current blocks and moves to it, builds a new block around it and so on. The search finally 
stops when the likelihood cannot be improved anymore or a maximal number of steps has been reached.

To compare the simulated data to the real one, Jaatha uses \emph{summary statistics} of the data.
As default, it calculates the Joint Site Frequency Spectrum (JSFS) of the data and further summarizes
it by evaluating different sums over the JSFS. Please refer to \cite{naduvilezhath_jaatha:_2011} for a detailed
description.


\section{Importing Your Data}
\noindent
To run Jaatha, you need to calculate the JSFS of your data. To do so, you can
use the function \verb@calculateJsfs()@. This function accepts data imported
with the \verb@read.dna()@ function from the package \emph{ape}. It assumes that you provide
a joined, aligned data set with multiple samples from two populations and -- optional 
but highly recommended -- one or more outgroup sequences. Additionally, you must
provide the numbers of the sequences in the dataset that belong to population
one, population two, and the outgroup, respectively.

Please consult the documentation of \emph{ape} in order to get more information
about \verb@read.dna()@. For example, the import of the data could look like this:  

<<LoadFastafiles, cache=TRUE>>=
library(ape)
# The path to the data
sample.file <- system.file('example_fasta_files/sample.fasta', 
                           package='jaatha')

# Reading the data
sample.data <- read.dna(sample.file, format='fasta', 
                        as.character=TRUE)

# Calculating the JSFS
sample.jsfs <- calculateJsfs(sample.data, 
                             pop1.rows=3:7, 
                             pop2.rows=8:12,
                             outgroup.row=1:2)
sample.jsfs
@

\vspace{1em}
\noindent
For the purpose of this HowTo, we will use a simulated JSFS, for which we 
know the real parameters:

<<Summary Statistics, cache=TRUE>>=
# Real parameters: M = 1, tau = 1 and theta = 10
real.pars <- c(1,1,10) 

# Simulate a JSFS with this parameters
sum.stats <- dm.simSumStats(dm, real.pars)
jsfs <- sum.stats$jsfs

# Print the upper left part of the JSFS
jsfs[1:7, 1:7]
@

\section{Running Jaatha}

\noindent
Jaatha is divided into two parts. First we find good starting
positions by simulating very coarsely across the entire parameter space. We call
this part \emph{initial search}. Afterwards a more thorough \emph{refined search}
is performed starting from the best positions of the first step. Before starting
the search, we need to set some options like our demographic model, the summary 
statistics of the real data, and a seed to ensure reproducibility:

<<Initialize>>=
jaatha <- Jaatha.initialize(dm, jsfs=jsfs, seed=12345, cores=2)
@

\noindent
For more options refer to \verb@?Jaatha.initialize@ or the Jaatha manual. If you
are running on Windows, skip the \verb@cores = 2@ option.

\subsection{The Initial Search}

\noindent
For the initial search, we divide the parameter space into equally-sized blocks by dividing 
each of the $n$ parameters ranges into \verb@blocks.per.par@ intervals such that we obtain 
$($\verb@blocks.per.par@$)^n$ blocks. Within each block we simulate \verb@sim@ data sets with 
-- on a logarithmic scale -- uniformly drawn parameter values within each block. To ensure 
a better sampling of the edges, we simulate in addition data sets for all corner points of 
each parameter block.

For these data sets we then fit the GLMs and estimate the parameter combination with the
maximal score\footnote{In this phase, Jaatha uses a score instead of the
likelihood for computational reasons. The likelihood is proportional to $\exp(\text{score})$. 
The higher the score, the higher the likelihood.}. 
Each of the blocks provides a single best parameter combination.

In R, the initial search is performed with the command

<<runInitialSearch, cache=TRUE>>=
jaatha <- Jaatha.initialSearch(jaatha, 
                               sim=100, 
                               blocks.per.par=2)
@

\noindent
To visualise the estimates for good stating positions sorted by score, type:
<<PrintStartPoints>>=
Jaatha.getStartingPoints(jaatha)
@
\noindent
Here, there is a big reduction in the likelihoods after the first three blocks. 
This is suggesting that we use the first three blocks as starting 
positions for the refined search. For now, we will just use the first point.

\subsection{The Refined Search}


\noindent
Now we can conduct the more thorough refined search described above to improve the
likelihood approximations. 

<<runRefinedSearch, cache=TRUE>>=
jaatha <- Jaatha.refinedSearch(jaatha, best.start.pos=1, sim=50)
@

\noindent
Here we use just one starting position for the sake of simplicity (e.g.
\verb@best.start.pos@ is set to one). In a real
analysis, it is recommended to start independent search from multiple starting
positions (use a value greater than one), to avoid getting stuck in local
maxima. 

During the search, we build a block with \verb@half.block.size@ in each direction
(on a logarithmic scale) at each step, and perform simulations for \verb@sim@ random parameter combinations within
this block (plus one for very corner). We use this information to estimate the composite maximum 
likelihood parameters within this block and take this value as new starting position for the next
step. 

The algorithm stops when the score has not changed more than \verb@epsilon@ for five consecutive 
steps or step \verb@max.steps@ is reached. To avoid getting stuck in local maxima, 
the \verb@weight@ option decreases the weight of simulations of previous blocks.

Finally the log composite likelihoods for the best ten parameter combinations are 
approximated using \verb@sim.final@ simulations. These are values printed at the 
end of the search. This matrix can also be accessed via

<<printLT>>=
likelihoods <- Jaatha.getLikelihoods(jaatha)
print(likelihoods[1:3, ])
@

%\begin{figure}
%  \begin{center}
%<<<label=fig1,fig=TRUE,echo=FALSE>>=
%<<printLT>>
%@
%  \end{center}
%  \caption{Likelihoods sorted by value}
%  \label{fig:one}
%\end{figure}

\section{Parallelization}
\noindent
On Linux and OS X, Jaatha can distribute the simulations on multiple CPU cores.
To use this feature, set the \verb@cores@ option during initialization. The
value of the option specifies the number of cores you want to use. Jaatha will
distribute its simulation evenly this cores. As for version $2.2$ on, the number
of cores no longer affects Jaatha's seeding system, e.g. you will get the same
results for the same seed no matter how many cores you use.

\section{Finite sites models}
\noindent
As described in \cite{mathew_why_2013}, you can use finite sites mutation 
models in Jaatha. However,
this currently only works on Linux and OS X and requires that Seq-Gen 
\citep{rambaut_seq-gen:_1997} is
installed on your system. On Debian GNU/Linux and it's derivates (Ubuntu, Mint) 
you can install it running 
\verb@apt-get install seq-gen@ as root. Otherwise download the current version from 
\url{http://tree.bio.ed.ac.uk/software/seqgen} and compile it according to the
instruction within the package. Jaatha will search for the Seq-Gen executable using 
your PATH variable. If you get an error that it is not able to find it, you can
specify the path to the executable using the \verb@Jaatha.setSeqgenExecutable@
function.

To create a finite sites model, you must specify a mutation model using the 
\verb@dm.setMutationModel@ function and add an outgroup to your model using
\verb@dm.addOutgroup@. Optionally, you can than add a mutation rate heterogeneity
to your model using \verb@dm.addMutationRateHeterogenity@.

\section{Confidence Intervals}
\noindent
From Version $2.2$ on, Jaatha also offers the function
\verb@Jaatha.confidenceIntervals@ to calculate parametric bootstrap
confidence intervals for the estimated parameters. Bootstrapping
requires to rerun the complete analysis multiple times, in the case of
parametric bootstrapping on simulated data. This means that in order to get
confidence intervals, you need to execute about $50$ to $100$ Jaatha runs, which can
be quite time consuming. Therefore, we recommend doing this only on a Linux/Mac
multicore system (the more cores the better), where the runs can be executed
at least partially in parallel. Set the \verb@cores@ option to the number of
cores you want to use (the individual Jaatha runs will always run on the single
core). We usually use up to $32$ cores on powerful computation servers for this.  
The confidence intervals are bias-correct and accelerated (BCa), as
described in Chapter $14.3$ of \cite{efron_introduction_1994}. 

\section{More on Demographic Models}
\noindent
The demographic model system can also deal with population size changes. There
are two functions that add a change in the size of a population to the model, 
\verb@dm.addSizeChange@ and \verb@dm.addGrowth@. 'SizeChanges' are instantaneous
changes in the population size, while 'Growth' refers to an exponential increase
or decrease in population size over time. Please keep in mind that models are always
specified looking backwards in time. Hence a size change affects the time from
the size changes time point on further backwards into the past. The
parametrisation of a model including both growth and time changes can be quite
challenging. As an example, here is the code for model S1.1 in
\cite{mathew_why_2013}:

<<advancedDM>>=
nLoci <- 100
rho <- 5
 
dm <- dm.createDemographicModel(c(25,25), nLoci, 1000)
dm <- dm.addMutation(dm, 5, 20, new.par.name="theta")
dm <- dm.addSpeciationEvent(dm, 0.017, 20, new.time.point.name="tau")
dm <- dm.addSymmetricMigration(dm, 0.005, 5, new.par.name="m")
# Everything but a fixed recombination rate does not make sense
dm <- dm.addRecombination(dm, fixed=rho)
 
# "SizeChange"s are instanious sizes changes (ms' -n, -N, -en and -eN)
dm <- dm.addSizeChange(dm, 0.05, 10, population=2, at.time="0", new.par.name="q")
 
# Parameters s1 + s2 have to be created separately, because they are no direct
# parameters of any command
dm <- dm.addParameter(dm, par.name="s1", 0.05, 10)
dm <- dm.addParameter(dm, par.name="s2", 0.05, 10)
dm <- dm.addSizeChange(dm, par.new=FALSE, parameter="s1+s2", population=1, at.time="tau")
 
# Growth is an exponential population expansion over time (e.g. ms' -g, -G, -eg and -eG)
dm <- dm.addGrowth(dm, par.new=FALSE, parameter="log(1/s1)/tau", population=1)
dm <- dm.addGrowth(dm, par.new=FALSE, parameter="log(q/s2)/tau", population=2)
@

\noindent
Forwards in time, this model consists of an ancestral population of relative
size $s1+s2$, which splits into two population at time $\tau$. These population
have size $s1$ and $s2$, and grow to their present relative sizes $1$ and $q.$  


\bibliographystyle{plainnat}
%\inputencoding{utf8}
\bibliography{jaatha}
%\inputencoding{utf8}

\end{document}
